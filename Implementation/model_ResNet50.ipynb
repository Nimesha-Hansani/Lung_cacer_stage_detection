{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nimesha\\AppData\\Local\\Temp\\ipykernel_12328\\3284378230.py:7: DeprecationWarning: Please use `median_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import median_filter\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import pydicom\n",
    "from scipy.ndimage.filters import median_filter\n",
    "from lungmask import mask\n",
    "import SimpleITK as sitk\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from easyfsl.samplers import TaskSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_hu(medical_image, image):\n",
    "    intercept = medical_image.RescaleIntercept\n",
    "    slope = medical_image.RescaleSlope\n",
    "    hu_image = image * slope + intercept\n",
    "    return hu_image\n",
    "\n",
    "def get_mask(filename, plot_mask=False, return_val=False):\n",
    "\n",
    "    input_image = sitk.ReadImage(filename)\n",
    "    mask_out = mask.apply(input_image)[0]  #default model is U-net(R231)\n",
    "\n",
    "    if return_val:\n",
    "        return mask_out\n",
    "\n",
    "def preprocess_images(img,dicom_image):\n",
    "\n",
    "    hu_image = transform_to_hu(dicom_image, img)\n",
    "    filtered_image = median_filter(hu_image, size=(3, 3))\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "class ResNet50Gray(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ResNet50Gray, self).__init__()\n",
    "        resnet50 = models.resnet50(pretrained=pretrained)\n",
    "        # Replace the input convolution layer to accept single channel grayscale images\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.conv1.weight.data = resnet50.conv1.weight.data[:,0,:,:].unsqueeze(1)\n",
    "        self.bn1 = resnet50.bn1\n",
    "        self.relu = resnet50.relu\n",
    "        self.maxpool = resnet50.maxpool\n",
    "        self.layer1 = resnet50.layer1\n",
    "        self.layer2 = resnet50.layer2\n",
    "        self.layer3 = resnet50.layer3\n",
    "        self.layer4 = resnet50.layer4\n",
    "        self.avgpool = resnet50.avgpool\n",
    "        self.fc = resnet50.fc\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DICOMDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "\n",
    "        self.img_labels = []\n",
    "        self.root_dir = root_dir\n",
    "        self.dcm_files = os.listdir(root_dir)\n",
    "\n",
    "        for filename in os.listdir(root_dir):\n",
    "            \n",
    "            image_name = filename\n",
    "            category = image_name[0]\n",
    "\n",
    "            if category =='A' :\n",
    "               label=1\n",
    "            elif category =='B':\n",
    "               label=2\n",
    "            elif category =='G':  \n",
    "               label=3 \n",
    "            elif category =='E':\n",
    "               label=4 \n",
    "            else : label=5        \n",
    "          \n",
    "            self.img_labels.append((image_name,label))\n",
    "\n",
    "    def __len__(self):\n",
    "        # print(len(self.img_labels))\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        dcm_file = self.dcm_files[idx]\n",
    "   \n",
    "        label_ch =dcm_file[0]\n",
    "        if label_ch =='A' :\n",
    "            label=1\n",
    "        elif label_ch =='B':\n",
    "            label=2\n",
    "        elif label_ch =='G':  \n",
    "            label=3 \n",
    "        elif label_ch =='E':\n",
    "            label=4  \n",
    "        else : label=5\n",
    "        dcm_path = os.path.join(self.root_dir, dcm_file)\n",
    "        \n",
    "        dicom_image= pydicom.dcmread(dcm_path)\n",
    "        image = np.array(dicom_image.pixel_array)\n",
    "        print(image.shape)\n",
    "\n",
    "        cleaned_image = preprocess_images(image,dicom_image)\n",
    "        masked_img=get_mask(dcm_path,plot_mask=True,return_val=True)\n",
    "    \n",
    "        mask_on_orginal = cleaned_image * masked_img\n",
    "        mask_on_orginal = cv2.resize(mask_on_orginal, (224, 224))\n",
    "       \n",
    "        image = mask_on_orginal.astype('float32')\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "       \n",
    "        image = torch.from_numpy(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrototypicalNetworks(nn.Module):\n",
    "    def __init__(self, backbone: nn.Module):\n",
    "        super(PrototypicalNetworks, self).__init__()\n",
    "        self.backbone = backbone\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        support_images: torch.Tensor,\n",
    "        support_labels: torch.Tensor,\n",
    "        query_images: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Predict query labels using labeled support images.\n",
    "        \"\"\"\n",
    "        # Extract the features of support and query images\n",
    "        z_support = self.backbone.forward(support_images)\n",
    "        print(z_support.shape)\n",
    "        z_query = self.backbone.forward(query_images)\n",
    "        print(z_query.shape)\n",
    "        \n",
    "        # Infer the number of different classes from the labels of the support set\n",
    "        n_way = len(torch.unique(support_labels))\n",
    "        # Prototype i is the mean of all instances of features corresponding to labels == i\n",
    "        z_proto = torch.cat(\n",
    "            [\n",
    "                z_support[torch.nonzero(support_labels == label)].mean(0)\n",
    "                for label in range(n_way)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        print(z_proto.shape)\n",
    "\n",
    "        # Compute the euclidean distance from queries to prototypes\n",
    "        dists = torch.cdist(z_query, z_proto)\n",
    "   \n",
    "\n",
    "        # And here is the super complicated operation to transform those distances into classification scores!\n",
    "        scores = -dists\n",
    "        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PrototypicalNetworks(\n",
       "  (backbone): ResNet50Gray(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convolutional_network = ResNet50Gray(pretrained=True)\n",
    "model = PrototypicalNetworks(convolutional_network)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run TaskSampler.ipynb\n",
    "\n",
    "dataset = DICOMDataset(root_dir='../IMAGES/TEST_SET/', transform=None)\n",
    "\n",
    "\n",
    "N_WAY = 4  # Number of classes in a task\n",
    "N_SHOT = 4  # Number of images per class in the support set\n",
    "N_QUERY = 3  # Number of images per class in the query set\n",
    "N_EVALUATION_TASKS = 3\n",
    "\n",
    "# The sampler needs a dataset with a \"get_labels\" method. Check the code if you have any doubt!\n",
    "dataset.get_labels = lambda: [\n",
    "    instance[1] for instance in dataset.img_labels\n",
    "]\n",
    "\n",
    "test_sampler = TaskSampler(\n",
    "    dataset, n_way=N_WAY, n_shot=N_SHOT, n_query=N_QUERY, n_tasks=N_EVALUATION_TASKS\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_sampler=test_sampler,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "    collate_fn=test_sampler.episodic_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2577.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2002.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2998.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2997.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 3998.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "100%|██████████| 5/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 9998.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1997.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1994.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    example_support_images,\n",
    "    example_support_labels,\n",
    "    example_query_images,\n",
    "    example_query_labels,\n",
    "    example_class_ids,\n",
    ") = next(iter(test_loader))\n",
    "\n",
    "print(len(example_support_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1000])\n",
      "torch.Size([12, 1000])\n",
      "torch.Size([4, 1000])\n",
      "Ground Truth / Predicted\n",
      "[4] / [4]\n",
      "[4] / [4]\n",
      "[4] / [4]\n",
      "[1] / [1]\n",
      "[1] / [1]\n",
      "[1] / [1]\n",
      "[3] / [2]\n",
      "[3] / [1]\n",
      "[3] / [2]\n",
      "[2] / [2]\n",
      "[2] / [2]\n",
      "[2] / [4]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "example_scores = model(\n",
    "    example_support_images,\n",
    "    example_support_labels,\n",
    "    example_query_images,\n",
    ").detach()\n",
    "\n",
    "\n",
    "\n",
    "_, example_predicted_labels = torch.max(example_scores.data, 1)\n",
    "\n",
    "print(\"Ground Truth / Predicted\")\n",
    "for i in range(len(example_query_labels)):\n",
    "    print(\n",
    "        f\"{[example_class_ids[example_query_labels[i]]]} / {[example_class_ids[example_predicted_labels[i]]]}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1993.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2001.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1993.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.81it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 5058.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 4970.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1999.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 4001.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1496.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.74it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 3664.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 3998.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1999.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 3988.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3003.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:28<00:56, 28.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1000])\n",
      "torch.Size([4, 1000])\n",
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.85it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2001.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1330.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 4024.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2000.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2000.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.77it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 4004.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 3993.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3000.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 3977.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1998.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1999.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 9988.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.69it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 4989.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1988.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:55<00:27, 27.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1000])\n",
      "torch.Size([4, 1000])\n",
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 3997.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2000.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 3984.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.83it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 5020.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1986.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1999.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 2993.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2000.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1990.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1999.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1992.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.79it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2629.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2000.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.86it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2000.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.84it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.71it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1000])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:23<00:00, 27.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 1000])\n",
      "torch.Size([4, 1000])\n",
      "Model tested on 3 tasks. Accuracy: 58.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_on_one_task(\n",
    "    support_images: torch.Tensor,\n",
    "    support_labels: torch.Tensor,\n",
    "    query_images: torch.Tensor,\n",
    "    query_labels: torch.Tensor,\n",
    ") -> [int, int]:\n",
    "    \"\"\"\n",
    "    Returns the number of correct predictions of query labels, and the total number of predictions.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        torch.max(\n",
    "            model(support_images, support_labels, query_images)\n",
    "            .detach()\n",
    "            .data,\n",
    "            1,\n",
    "        )[1]\n",
    "        == query_labels\n",
    "    ).sum().item(), len(query_labels)\n",
    "\n",
    "\n",
    "def evaluate(data_loader: DataLoader):\n",
    "    # We'll count everything and compute the ratio at the end\n",
    "    total_predictions = 0\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # eval mode affects the behaviour of some layers (such as batch normalization or dropout)\n",
    "    # no_grad() tells torch not to keep in memory the whole computational graph (it's more lightweight this way)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for episode_index, (\n",
    "            support_images,\n",
    "            support_labels,\n",
    "            query_images,\n",
    "            query_labels,\n",
    "            class_ids,\n",
    "        ) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "\n",
    "            correct, total = evaluate_on_one_task(\n",
    "                support_images, support_labels, query_images, query_labels\n",
    "            )\n",
    "\n",
    "            total_predictions += total\n",
    "            correct_predictions += correct\n",
    "\n",
    "    print(\n",
    "        f\"Model tested on {len(data_loader)} tasks. Accuracy: {(100 * correct_predictions/total_predictions):.2f}%\"\n",
    "    )\n",
    "\n",
    "\n",
    "evaluate(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

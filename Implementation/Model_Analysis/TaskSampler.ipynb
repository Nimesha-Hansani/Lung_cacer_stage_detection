{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nimesha\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: 'Could not find module 'C:\\Users\\Nimesha\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import Dict, Iterator, List, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "from easyfsl.datasets import FewShotDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler\n",
    "from easyfsl.datasets import FewShotDataset\n",
    "import random\n",
    "from typing import Dict, Iterator, List, Tuple, Union\n",
    "from torch import Tensor\n",
    "\n",
    "GENERIC_TYPING_ERROR_MESSAGE = (\n",
    "    \"Check out the output's type of your dataset's __getitem__() method.\"\n",
    "    \"It must be a Tuple[Tensor, int] or Tuple[Tensor, 0-dim Tensor].\"\n",
    ")\n",
    "\n",
    "class TaskSampler(Sampler):\n",
    "    \"\"\"\n",
    "    Samples batches in the shape of few-shot classification tasks. At each iteration, it will sample\n",
    "    n_way classes, and then sample support and query images from these classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: FewShotDataset,\n",
    "        n_way: int,\n",
    "        n_shot: int,\n",
    "        n_query: int,\n",
    "        n_tasks: int,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            dataset: dataset from which to sample classification tasks. Must have implement get_labels() from\n",
    "                FewShotDataset.\n",
    "            n_way: number of classes in one task\n",
    "            n_shot: number of support images for each class in one task\n",
    "            n_query: number of query images for each class in one task\n",
    "            n_tasks: number of tasks to sample\n",
    "        \"\"\"\n",
    "        super().__init__(data_source=None)\n",
    "        self.n_way = n_way\n",
    "        self.n_shot = n_shot\n",
    "        self.n_query = n_query\n",
    "        self.n_tasks = n_tasks\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        self.items_per_label: Dict[int, List[int]] = {}\n",
    "        for item, label in enumerate(dataset.get_labels()):\n",
    "            # print(item,label)\n",
    "            if label in self.items_per_label:\n",
    "                self.items_per_label[label].append(item)\n",
    "            else:\n",
    "                self.items_per_label[label] = [item]\n",
    "\n",
    "        \n",
    "            \n",
    "\n",
    "        self._check_dataset_size_fits_sampler_parameters()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.n_tasks\n",
    "    \n",
    "    def _check_dataset_size_fits_sampler_parameters(self):\n",
    "        \"\"\"\n",
    "        Check that the dataset size is compatible with the sampler parameters\n",
    "        \"\"\"\n",
    "        self._check_dataset_has_enough_labels()\n",
    "        self._check_dataset_has_enough_items_per_label()\n",
    "\n",
    "    def _check_dataset_has_enough_labels(self):\n",
    "        if self.n_way > len(self.items_per_label):\n",
    "            raise ValueError(\n",
    "                f\"The number of labels in the dataset ({len(self.items_per_label)} \"\n",
    "                f\"must be greater or equal to n_way ({self.n_way}).\"\n",
    "            )\n",
    "\n",
    "    def _check_dataset_has_enough_items_per_label(self):\n",
    "        number_of_samples_per_label = [\n",
    "            len(items_for_label) for items_for_label in self.items_per_label.values()\n",
    "        ]\n",
    "        minimum_number_of_samples_per_label = min(number_of_samples_per_label)\n",
    "        label_with_minimum_number_of_samples = number_of_samples_per_label.index(\n",
    "            minimum_number_of_samples_per_label\n",
    "        )\n",
    "        if self.n_shot + self.n_query > minimum_number_of_samples_per_label:\n",
    "            raise ValueError(\n",
    "                f\"Label {label_with_minimum_number_of_samples} has only {minimum_number_of_samples_per_label} samples\"\n",
    "                f\"but all classes must have at least n_shot + n_query ({self.n_shot + self.n_query}) samples.\"\n",
    "            )\n",
    "\n",
    "\n",
    "    def __iter__(self) -> Iterator[List[int]]:\n",
    "       \n",
    "        for i in range(self.n_tasks):\n",
    "         \n",
    "            yield torch.cat(\n",
    "                [\n",
    "                    # pylint: disable=not-callable\n",
    "                    torch.tensor(\n",
    "                        random.sample(\n",
    "                            self.items_per_label[label], self.n_shot + self.n_query\n",
    "                        )\n",
    "                    )\n",
    "                    # pylint: enable=not-callable\n",
    "                    for label in random.sample(sorted(self.items_per_label.keys()), self.n_way)\n",
    "                ]\n",
    "            ).tolist()\n",
    "    \n",
    "    def episodic_collate_fn(  self,input_data: List[Tuple[Tensor, Union[Tensor, int]]]\n",
    "    ) -> Tuple[Tensor, Tensor, Tensor, Tensor, List[int]]:\n",
    "        \n",
    "       \n",
    "        input_data_with_int_labels = self._cast_input_data_to_tensor_int_tuple(input_data)\n",
    "        true_class_ids = list({x[1] for x in input_data_with_int_labels})\n",
    "        \n",
    "        all_images = torch.cat([x[0].unsqueeze(0) for x in input_data_with_int_labels])\n",
    "        all_images = all_images.reshape(\n",
    "            (self.n_way, self.n_shot + self.n_query, *all_images.shape[1:])\n",
    "        )\n",
    "\n",
    "        # pylint: disable=not-callable\n",
    "        all_labels = torch.tensor(\n",
    "            [true_class_ids.index(x[1]) for x in input_data_with_int_labels]\n",
    "        ).reshape((self.n_way, self.n_shot + self.n_query))\n",
    "        # pylint: enable=not-callable\n",
    "        support_images = all_images[:, : self.n_shot].reshape(\n",
    "            (-1, *all_images.shape[2:])\n",
    "        )\n",
    "\n",
    "\n",
    "        query_images = all_images[:, self.n_shot :].reshape((-1, *all_images.shape[2:]))\n",
    "        support_labels = all_labels[:, : self.n_shot].flatten()\n",
    "        query_labels = all_labels[:, self.n_shot :].flatten()\n",
    "        return (\n",
    "            support_images,\n",
    "            support_labels,\n",
    "            query_images,\n",
    "            query_labels,\n",
    "            true_class_ids,\n",
    "        )\n",
    "        \n",
    "\n",
    "    \n",
    "    def _cast_input_data_to_tensor_int_tuple(\n",
    "                           self,input_data: List[Tuple[Tensor, Union[Tensor, int]]]\n",
    "    ) -> List[Tuple[Tensor, int]]:\n",
    "        \"\"\"\n",
    "        Check the type of the input for the episodic_collate_fn method, and cast it to the right type if possible.\n",
    "        Args:\n",
    "            input_data: each element is a tuple containing:\n",
    "                - an image as a torch Tensor\n",
    "                - the label of this image as an int or a 0-dim tensor\n",
    "        Raises:\n",
    "            TypeError : Wrong type of input images or labels\n",
    "            ValueError: Input label is not a 0-dim tensor\n",
    "        \"\"\"\n",
    "        for image, label in input_data:\n",
    "            \n",
    "            if not isinstance(image, Tensor):\n",
    "                raise TypeError(\n",
    "                    f\"Illegal type of input instance: {type(image)}. \"\n",
    "                    + GENERIC_TYPING_ERROR_MESSAGE\n",
    "                )\n",
    "            if not isinstance(label, int):\n",
    "                if not isinstance(label, Tensor):\n",
    "                    raise TypeError(\n",
    "                        f\"Illegal type of input label: {type(label)}. \"\n",
    "                        + \"GENERIC_TYPING_ERROR_MESSAGE\"\n",
    "                    )\n",
    "                if label.dtype not in {\n",
    "                    torch.uint8,\n",
    "                    torch.int8,\n",
    "                    torch.int16,\n",
    "                    torch.int32,\n",
    "                    torch.int64,\n",
    "                }:\n",
    "                    raise TypeError(\n",
    "                        f\"Illegal dtype of input label tensor: {label.dtype}. \"\n",
    "                        + \"GENERIC_TYPING_ERROR_MESSAGE\"\n",
    "                    )\n",
    "                if label.ndim != 0:\n",
    "                    raise ValueError(\n",
    "                        f\"Illegal shape for input label tensor: {label.shape}. \"\n",
    "                        + \"GENERIC_TYPING_ERROR_MESSAGE\"\n",
    "                    )\n",
    "\n",
    "        return [(image, int(label)) for (image, label) in input_data]\n",
    "\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

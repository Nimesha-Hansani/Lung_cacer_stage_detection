{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nimesha\\AppData\\Local\\Temp\\ipykernel_20280\\3183033577.py:8: DeprecationWarning: Please use `median_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
      "  from scipy.ndimage.filters import median_filter\n"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import os\n",
    "import pydicom\n",
    "import matplotlib.pyplot as plt\n",
    "from lungmask import mask\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "from scipy.ndimage.filters import median_filter\n",
    "from scipy.ndimage import affine_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_hu(medical_image, image):\n",
    "    intercept = medical_image.RescaleIntercept\n",
    "    slope = medical_image.RescaleSlope\n",
    "    hu_image = image * slope + intercept\n",
    "\n",
    "    return hu_image\n",
    "\n",
    "def tilt_correction(medical_image,image):\n",
    "    # Calculate the tilt angle using the metadata\n",
    "    tilt_angle = medical_image.SliceLocation - medical_image.ImagePositionPatient[2]\n",
    "  \n",
    "    # Define the transformation matrix\n",
    "    theta = tilt_angle * np.pi / 180\n",
    "    cos_theta, sin_theta = np.cos(theta), np.sin(theta)\n",
    "    M = np.array([[cos_theta, -sin_theta, 0],\n",
    "                  [sin_theta, cos_theta, 0],\n",
    "                  [0, 0, 1]])\n",
    "\n",
    "    # Perform the affine transformation\n",
    "    transformed_data = affine_transform(image , M)\n",
    "\n",
    "    return transformed_data\n",
    "\n",
    "def crop_image(image, display=False):\n",
    "\n",
    "    # Define the crop boundaries\n",
    "    top = 50\n",
    "    bottom = image.shape[0] - 50\n",
    "    left = 50\n",
    "    right = image.shape[1] - 50\n",
    "\n",
    "    # Crop the pixel data\n",
    "    cropped_data = image[top:bottom, left:right]\n",
    "\n",
    "    return cropped_data\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(filename, plot_mask=False, return_val=False):\n",
    "\n",
    "    input_image = sitk.ReadImage(filename)\n",
    "    mask_out = mask.apply(input_image)[0]  #default model is U-net(R231)\n",
    "    # if plot_mask: \n",
    "    #     fig = plt.figure(figsize=(4, 4))\n",
    "    #     # plt.imshow(mask_out)\n",
    "        \n",
    "    #     # plt.imshow(mask_out)\n",
    "    if return_val:\n",
    "        return mask_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_images(img,dicom_image):\n",
    "\n",
    "    hu_image = transform_to_hu(dicom_image, img)\n",
    "\n",
    "    # medianl filter for noise reduction \n",
    "    # Apply the median filter with a kernel size of 3x3\n",
    "    filtered_image = median_filter(hu_image, size=(3, 3))\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "def change_dimensions(img):\n",
    "\n",
    "\n",
    "    #crop unnecessary parts from image\n",
    "    croppedImage = crop_image(img)\n",
    "\n",
    "    # Resize the image to size (28, 28)\n",
    "    resized_image = np.resize(croppedImage, (28, 28))\n",
    "\n",
    "    # Convert the numpy array to a PyTorch tensor\n",
    "    tensor = torch.from_numpy(resized_image)\n",
    "\n",
    "    # Reshape the tensor to have dimensions (1, 28, 28) to represent one color channel\n",
    "    tensor = tensor.reshape((1, 28, 28))\n",
    "    print(tensor.shape)\n",
    "\n",
    "    # Normalize the tensor to have values between 0 and 1\n",
    "    tensor = tensor.float() / 255.0\n",
    "\n",
    "    # Add two more dimensions to represent the other two color channels (RGB)\n",
    "    tensor = tensor.repeat(3, 1, 1)\n",
    "\n",
    "    # Transpose the tensor to have dimensions (3, 28, 28)\n",
    "    tensor = torch.transpose(tensor, 0, 2)\n",
    "    tensor = torch.transpose(tensor, 1, 2)\n",
    "\n",
    "    print(type(tensor))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Load the pre-trained VGG16 model with ImageNet weights\n",
    "VGG16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the layers in the pre-trained model so that they are not retrained\n",
    "for layer in VGG16_model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_images(folder_path):\n",
    "\n",
    "    # Initialize dictionaries to store support features and prototypes\n",
    "    features = {}\n",
    "\n",
    "    # Initialize a figure with a 4x5 grid of subplots\n",
    "    # fig, axes = plt.subplots(nrows=4, ncols=5, figsize=(16, 12))\n",
    "\n",
    "    for i, sub_folder in enumerate(os.listdir(folder_path)):\n",
    "            \n",
    "            sub_folder_path = os.path.join(folder_path+'/'+ sub_folder)\n",
    "        \n",
    "            label =sub_folder[-1]\n",
    "            print(label)\n",
    "\n",
    "            # Initialize list to store support features for current class\n",
    "            features[label] = []\n",
    "                \n",
    "            for j, dcm_file in enumerate(os.listdir(sub_folder_path)):\n",
    "                \n",
    "                file_path = os.path.join(sub_folder_path+'/'+ dcm_file)\n",
    "                \n",
    "                dicom_image = pydicom.dcmread(file_path)\n",
    "                img = dicom_image.pixel_array\n",
    "\n",
    "                cleaned_image = preprocess_images(img,dicom_image)\n",
    "                masked_img=get_mask(file_path,plot_mask=True,return_val=True)\n",
    "                mask_on_orginal = cleaned_image*masked_img\n",
    "\n",
    "                resized_img = cv2.resize(mask_on_orginal, (224, 224))\n",
    "\n",
    "                normalized_img = resized_img.astype('float32') / 255\n",
    "\n",
    "                if len(normalized_img.shape) == 2:\n",
    "                    normalized_img = np.stack([normalized_img] * 3, axis=-1)\n",
    "\n",
    "                input_img = np.expand_dims(normalized_img, axis=0)   \n",
    "\n",
    "\n",
    "                #apply vgg16 model for  extract features \n",
    "                feature_vec = VGG16_model.predict(input_img)\n",
    "               \n",
    "                # Append features to support_features\n",
    "                features[label].append(feature_vec[0]) \n",
    "\n",
    " \n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "# Set the path to the folder containing the sub folders \n",
    "support_folder_path = 'C:/Users/Nimesha/Documents/MSC_RESEARCH/IMAGES/Support_Set'\n",
    "query_folder_path   =  'C:/Users/Nimesha/Documents/MSC_RESEARCH/IMAGES/Query_Set'\n",
    "\n",
    "\n",
    "support_features=read_images(support_folder_path)\n",
    "query_features=read_images(query_folder_path)\n",
    "\n",
    "print(type(support_features))\n",
    "print(type(query_features))\n",
    "\n",
    "\n",
    "\n",
    "# Initialize empty dictionary to store prototypes for each class\n",
    "prototypes = {}\n",
    "\n",
    "# Calculate the prototype for each class\n",
    "for label, features in support_features.items():\n",
    "    \n",
    "    # Convert list of feature vectors to numpy array\n",
    "    features_array = np.array(features)\n",
    "    \n",
    "    # Calculate mean of feature vectors\n",
    "    prototype = np.mean(features_array, axis=0)\n",
    "    # Store prototype for current class in dictionary\n",
    "    prototypes[label] = prototype\n",
    "\n",
    "print(type(prototypes))\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Iterate over each query image and calculate the distance to each prototype\n",
    "for query_label, query_features in query_features.items():\n",
    "\n",
    "    print(query_label)\n",
    "    # Convert list of feature vectors to numpy array\n",
    "    query_features_array = np.array(query_features)\n",
    "    \n",
    "    # Initialize an empty list to store the distances between the query image and each prototype\n",
    "    distances = []\n",
    "    \n",
    "    for prototype_label, prototype in prototypes.items():\n",
    "        # Calculate the Euclidean distance between the query image features and the prototype features\n",
    "        distance = np.linalg.norm(query_features_array - prototype, axis=1)\n",
    "        \n",
    "        # Append the distance to the list of distances\n",
    "        distances.append(distance)\n",
    "    \n",
    "    # Convert the list of distances to a 2D numpy array\n",
    "    distances_array = np.array(distances)\n",
    "    \n",
    "    # The classification score is -1 * the distance, so invert the distances\n",
    "    scores = -1 * distances_array\n",
    "    \n",
    "    # The predicted class is the one with the highest score\n",
    "    predicted_label = np.argmax(scores)\n",
    "    \n",
    "    # Print the predicted label for the query image\n",
    "    print(f\"Query image with label {query_label} is predicted to belong to class {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 188ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 83ms/step\n",
      "B\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.01it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 88ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "100%|██████████| 6/6 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 88ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.89it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 78ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step\n",
      "E\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "100%|██████████| 3/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 92ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.92it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 91ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 4000.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 89ms/step\n",
      "G\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.95it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 9998.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.96it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 95ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.93it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.80it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2000.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2001.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 88ms/step\n",
      "A\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n",
      "B\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.90it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step\n",
      "E\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.91it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2000.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n",
      "G\n",
      "INFO:root:No GPU support available, will use CPU. Note, that this is significantly slower!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]\n",
      "100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step\n",
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query image with label A is predicted to belong to class 1\n",
      "Query image with label B is predicted to belong to class 1\n",
      "Query image with label E is predicted to belong to class 1\n",
      "Query image with label G is predicted to belong to class 1\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

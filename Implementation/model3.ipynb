{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import pydicom\n",
    "from scipy.ndimage.filters import median_filter\n",
    "from lungmask import mask\n",
    "import SimpleITK as sitk\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from easyfsl.samplers import TaskSampler\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_hu(medical_image, image):\n",
    "    intercept = medical_image.RescaleIntercept\n",
    "    slope = medical_image.RescaleSlope\n",
    "    hu_image = image * slope + intercept\n",
    "\n",
    "    return hu_image\n",
    "\n",
    "def get_mask(filename, plot_mask=False, return_val=False):\n",
    "\n",
    "    input_image = sitk.ReadImage(filename)\n",
    "    mask_out = mask.apply(input_image)[0]  #default model is U-net(R231)\n",
    "\n",
    "    if return_val:\n",
    "        return mask_out\n",
    "\n",
    "def preprocess_images(img,dicom_image):\n",
    "\n",
    "    hu_image = transform_to_hu(dicom_image, img)\n",
    "\n",
    "    # medianl filter for noise reduction \n",
    "    # Apply the median filter with a kernel size of 3x3\n",
    "    filtered_image = median_filter(hu_image, size=(3, 3))\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "from torch.utils.data import Dataset\n",
    "import tensorflow as tf\n",
    "\n",
    "class DICOMDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.dcm_files = os.listdir(root_dir)\n",
    "        self.image_list = []\n",
    "        self.categories=['A','B','G','E']\n",
    "        \n",
    "        for filename in os.listdir(root_dir):\n",
    "            \n",
    "            image_name = filename\n",
    "            category = image_name[0]\n",
    "\n",
    "            self.image_list.append((image_name,category))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dcm_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        dcm_file = self.dcm_files[idx]\n",
    "        label =dcm_file[0]\n",
    "        dcm_path = os.path.join(self.root_dir, dcm_file)\n",
    "        dicom_image= pydicom.dcmread(dcm_path)\n",
    "        img = np.array(dicom_image.pixel_array)\n",
    "        \n",
    "        cleaned_image = preprocess_images(img,dicom_image)\n",
    "\n",
    "        masked_img=get_mask(dcm_path,plot_mask=True,return_val=True)\n",
    "        mask_on_orginal = cleaned_image*masked_img\n",
    "        resized_img = cv2.resize(mask_on_orginal, (224, 224))\n",
    "        # convert grayscale to RGB\n",
    "       \n",
    "        normalized_img = resized_img.astype('float32') / 255\n",
    "        \n",
    "        # Apply the transformation only if it is not None\n",
    "        if self.transform is not None:\n",
    "           normalized_img = self.transform(normalized_img)\n",
    "        \n",
    "        if label=='A' : nu_label=1\n",
    "        elif label=='B' : nu_label=2\n",
    "        elif label=='E' : nu_label=3\n",
    "        elif label=='G'  : nu_label=4\n",
    "        \n",
    "        # image=tf.convert_to_tensor(normalized_img)\n",
    "        return normalized_img,nu_label\n",
    "    \n",
    "    def get_labels(self):\n",
    "        return [item[0] for item in self.image_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        # modify the first convolutional layer to accept one input channel\n",
    "        self.features = models.vgg16(pretrained=True).features\n",
    "        self.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1)\n",
    "        # remove the last fully connected layer (classifier)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(*list(models.vgg16(pretrained=True).classifier.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "\n",
    "dataset = DICOMDataset(root_dir='../IMAGES/DICOM_SUPPORT/', transform=None)\n",
    "\n",
    "\n",
    "N_WAY = 4  # Number of classes in a task\n",
    "N_SHOT = 2  # Number of images per class in the support set\n",
    "N_QUERY = 1  # Number of images per class in the query set\n",
    "N_EVALUATION_TASKS = 10\n",
    "\n",
    "# The sampler needs a dataset with a \"get_labels\" method. Check the code if you have any doubt!\n",
    "dataset.get_labels = lambda: [\n",
    "    instance[1] for instance in dataset.image_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = TaskSampler(\n",
    "    dataset, n_way=N_WAY, n_shot=N_SHOT, n_query=N_QUERY, n_tasks=N_EVALUATION_TASKS\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset,\n",
    "    batch_sampler=test_sampler,\n",
    "    num_workers=0,\n",
    "    pin_memory=True,\n",
    "  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test_loader:\n",
    "    print(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
